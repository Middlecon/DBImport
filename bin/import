#!/usr/bin/env python3
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import sys
import getopt
import logging
from common import constants as constant
from DBImportOperation import import_operations
from DBImportOperation import copy_operations
from DBImportOperation import etl_operations

def printHelp():
	print ("Options:")
	print ("  --help             Show this help message and exit")
	print ("  -v, --debug        Turn on extensive debug output. This will print passwords in cleartext, so use with caution")
	print ("  -V, --version      Displays the version of DBImport")
	print ("  --skipSqoop        Dont run the sqoop command. Useful when the Parquet files are correct and you need to recreate Hive tables")
	print ("  --ignoreTime       Ignores the start and stop time for the table. Will run outside that window regardless")
	print ("  --resetStage       Starts from the beginning regardless of previous problems")
	print ("  -h [Hive Database], --Hive_DB=[Hive Database]")
	print ("                     Hive database")
	print ("  -t [Hive Table], --Hive_Table=[Hive Table]")
	print ("                     Hive table")
	print ("  -I, -1             Only run functions in Import Phase. ")
	print ("  -C                 Only run functions in Copy Phase. ")
	print ("  -E, -2             Only run functions in ETL Phase.")
	print ("  -f [Function], --function=[Function]")
	print ("                     Only run the specified function. This is used for debugging and when migrating from")
	print ("                     bash based DBImport scripts. Using a function ignore what ever stage the import is in.")
	print ("                     Use with caution!")
	print ("                     Valid function options are:")
	print ("                     - getSourceTableSchema")
	print ("                     - sqoop")
	print ("                     - createImportTable")
	print ("                     - getSourceTableRowCount")
	print ("                     - getImportTableRowCount")
	print ("                     - getTargetTableRowCount")
	print ("                     - createTargetTable")
	print ("                     - createHistoryTable")
	print ("                     - createDeleteTable")
	print ("                     - removeHiveLocks")
	print ("                     - truncateTargetTable")
	print ("                     - loadDataFromImportTable")
	print ("                     - mergeTable")
	print ("                     - createStatistics")
	print ("                     - copySchema")
	print ("                     - copyFiles")
	sys.exit(1)
	
def printBox(messageList):
	# This code is not completed. It was a way to easily create the Ascii boxes used in the import, but we are still using hard-coded boxes. One day.....
	if type(messageList) is not list:
		messageList = [messageList]

	startLine = ""
	stopLine = ""
	maxLength = 0
	for message in messageList:
		if len(message) > maxLength:
			maxLength = len(message)

	for i in range(maxLength):
		startLine += "_"
		stopLine += "_"

	print(startLine)
	for message in messageList:
		if len(message) > maxLength:
			maxLength = len(message)
	print(stopLine)

def main(argv):

	try:
		opts, args = getopt.getopt(argv, "vVICE12f:h:t:", ["version", "help", "function=", "Hive_DB=", "Hive_Table=", "debug", "skipSqoop", "ignoreTime", "resetStage", "skipHiveTest"])
	except getopt.GetoptError:
		printHelp()

	version = "0.10"
	Hive_DB = None
	Hive_Table = None
	runOnlyFunction = None
	loggingLevel = logging.INFO
	skipSqoop = False
	runImportPhase = False
	runCopyPhase = False
	runCopyPhaseByForce = False
	runETLPhase = False
	displayVersion = False
	ignoreTime = False
	resetStage = False
	skipHiveTest = False

	if  len(opts) == 0:
		printHelp()

	for opt, arg in opts:
		if opt in ("-h", "--Hive_DB"):
			Hive_DB = arg
		elif opt in ("-t", "--Hive_Table"):
			Hive_Table = arg
		elif opt in ("-v", "--debug"):
			loggingLevel = logging.DEBUG
		elif opt in ("-V", "--version"):
			displayVersion = True
		elif opt == "--skipSqoop":
			skipSqoop = True
		elif opt == "--skipHiveTest":
			skipHiveTest = True
		elif opt == "--resetStage":
			resetStage = True
		elif opt == "--ignoreTime":
			ignoreTime = True
		elif opt in ("-f", "--function"):
			runOnlyFunction = arg
		elif opt == "--help":
			printHelp()
		elif opt == "-1":
			runImportPhase = True
		elif opt == "-2":
			runETLPhase = True
		elif opt == "-I":
			runImportPhase = True
		elif opt == "-C":
			runCopyPhase = True
		elif opt == "-E":
			runETLPhase = True

	if displayVersion == True:
		print("DBImport version: %s"%(constant.VERSION))
		sys.exit(0)

	if Hive_DB == None or Hive_Table == None:
		printHelp()

	if runImportPhase == False and runETLPhase == False and runCopyPhase == False:
		# If nothing is specified we run all stages
		runImportPhase = True
		runCopyPhase = True
		runETLPhase = True

	if runOnlyFunction != None:
		if runOnlyFunction not in ("getSourceTableSchema", "onlyMain", "sqoop", "createImportTable", "getImportTableRowCount", "getTargetTableRowCount", "createTargetTable", "removeHiveLocks", "truncateTargetTable", "loadDataFromImportTable", "createStatistics", "getSourceTableRowCount", "mergeTable", "createHistoryTable", "createDeleteTable", "copySchema", "copyFiles"):
			printHelp()

	# Initiate the logging functions with the correct level
	if loggingLevel == logging.DEBUG:
		logging.basicConfig(format='%(levelname)s %(funcName)s - %(message)s', level=loggingLevel)
	else:
		logging.basicConfig(format='%(levelname)s - %(message)s', level=loggingLevel)

	# Font created at http://patorjk.com/software/taag/#p=display&f=Big&t=DBImport%20-%20Import
	sys.stdout.write(u"\u001b[35m")  # Magenta
	sys.stdout.flush()
	print("")
	print(" _____  ____ _____                            _              _____                            _   ")
	print("|  __ \|  _ \_   _|                          | |            |_   _|                          | |  ")
	print("| |  | | |_) || |  _ __ ___  _ __   ___  _ __| |_   ______    | |  _ __ ___  _ __   ___  _ __| |_ ")
	print("| |  | |  _ < | | | '_ ` _ \| '_ \ / _ \| '__| __| |______|   | | | '_ ` _ \| '_ \ / _ \| '__| __|")
	print("| |__| | |_) || |_| | | | | | |_) | (_) | |  | |_            _| |_| | | | | | |_) | (_) | |  | |_ ")
	print("|_____/|____/_____|_| |_| |_| .__/ \___/|_|   \__|          |_____|_| |_| |_| .__/ \___/|_|   \__|")
	print("                            | |                                             | |                   ")
	print("                            |_|                                             |_|                   ")
	sys.stdout.write(u"\u001b[0m")  # Reset
	sys.stdout.flush()
	print("")
	print("Version: %s"%(constant.VERSION))
	print("")
	print("")
	
	# Initiate the master class for all import operations
	import_operation = import_operations.operation(Hive_DB, Hive_Table)
	copy_operation = copy_operations.operation()
	etl_operation = etl_operations.operation()

	copyDestinations = copy_operation.getCopyDestinations(hiveDB = Hive_DB, hiveTable = Hive_Table)

	# Get the name of the different phases we are going to execute
	importPhase = import_operation.import_config.importPhase 
	etlPhase    = import_operation.import_config.etlPhase 
	importPhaseDescription = import_operation.import_config.importPhaseDescription 
	etlPhaseDescription    = import_operation.import_config.etlPhaseDescription 

	slaveTable = import_operation.import_config.copy_slave

	print("The following table will be imported")
	print("______________________________________________________________________________")
	print("")
	if import_operation.import_config.import_type != None and import_operation.import_config.import_type != "":
		print("Import Type (OLD):        %s"%(import_operation.import_config.import_type))
		print("Import description (OLD): %s"%(import_operation.import_config.import_type_description))
	print("Import Phase:             %s"%(importPhaseDescription))

	if copyDestinations == None:
		print("Copy destinations:        No cluster copy")
	else:
		firstRow = True
		for dest in copyDestinations:
			if firstRow == True:
				print("Copy destinations:        %s"%(dest.replace(';', " - ")))
				firstRow = False
			else:
				print("                          %s"%(dest.replace(';', " - ")))

	print("ETL Phase:                %s"%(etlPhaseDescription))
#	print("Export Phase:             %s"%("No Export"))
	print("Source hostname:          %s"%(import_operation.import_config.common_config.jdbc_hostname))
	print("Source database type:     %s"%(import_operation.import_config.common_config.jdbc_servertype))
	print("Source database:          %s"%(import_operation.import_config.common_config.jdbc_database))
	if import_operation.import_config.source_schema != "-":
		print("Source schema:            %s"%(import_operation.import_config.source_schema))
	print("Source table:             %s"%(import_operation.import_config.source_table))
	print("Hive database:            %s"%(import_operation.import_config.Hive_DB))
	print("Hive table:               %s"%(import_operation.import_config.Hive_Table))
	print("______________________________________________________________________________")
	print("")
	sys.stdout.flush()

	stage = import_operation.getStage()

	# Check if the configured Hive database exists
	import_operation.checkHiveDB(Hive_DB.lower())

	if ignoreTime == False:
#		# Checking if we are allowed to use the configued JDBC connection at this time
		import_operation.checkTimeWindow()

	if import_operation.import_config.common_config.checkKerberosTicket() == False:
		logging.error("There is no valid Kerberos ticket available. Please create one before running this command")
		import_operation.remove_temporary_files()
		sys.exit(1)

	if resetStage == True:
		import_operation.setStage(0, force=True)
		stage = 0

	if copy_operation.isPreviousCopyCompleted() == False and stage < 2099 :
		logging.error("There is a previous copy that isnt completed yet. This import cant continue until that copy is completed") 
		import_operation.remove_temporary_files()
		sys.exit(1)


	if ( runImportPhase == True and runETLPhase == False and runCopyPhase == False ) and runOnlyFunction == None:
		print(" _____________________ ")
		print("|                     |")
		print("| Import Phase only   |")
		print("|_____________________|")
		print("")
		print("")
		if stage > 1999:
			print("Warning: There is already an ongoing import with a stage that already passed the Import stage. Nothing will happen")

	if ( runImportPhase == False and runETLPhase == False  and runCopyPhase == True) and runOnlyFunction == None:
		print(" ___________________")
		print("|                   |")
		print("| Copy Phase only   |")
		print("|___________________|")
		print("")
		print("")
		if stage > 2999:
			print("Warning: There is already an ongoing import with a stage that already passed the Copy stage. Nothing will happen")
		if stage < 2000 and stage != 1049 and stage != 1149 and stage != 1249 and stage != 0:
			print("Warning: There is already an ongoing import but it havent completed the Import stage yet. Nothing will happen")

		# As we can run copy phase only, we will just keep the stage info in memories for these imports
		if stage == 0:
			import_operation.setStageOnlyInMemory()
			runCopyPhaseByForce = True

	if ( runImportPhase == False and runETLPhase == True  and runCopyPhase == False) and runOnlyFunction == None:
		print(" __________________")
		print("|                  |")
		print("| ETL Phase only   |")
		print("|__________________|")
		print("")
		print("")

	if runOnlyFunction != None:
		print(" _______________________________________________________ ")
		print("|                                                       |")
		print("| This is not a full import as a function was specified |") 	
		print("|_______________________________________________________|")
		print("")
		print("")

		import_operation.setStageOnlyInMemory()

	if stage > 0 and stage < 1000:
		# TODO: Remove this once everything is migrated to python version
		print(" ________________________________________________________ ")
		print("|                                                        |")
		print("| ERROR: Stage information incorrect. Did you run the    |") 	
		print("|        python version of DBImport last time?           |") 	
		print("|________________________________________________________|")
		print("")
		print("")
		import_operation.remove_temporary_files()
		sys.exit(1)

	if runImportPhase == True and runETLPhase == False and ( stage == 1049 or stage == 1149 ):
		print(" ______________________________________ ")
		print("|                                      |")
		print("| Import Phase is already completed.   |") 
		print("| To continue, run with option '-2'    |") 	
		print("|______________________________________|")

		import_operation.remove_temporary_files()
		sys.exit(0)

	sys.stdout.flush()


	if import_operation.import_config.common_config.getConfigValue(key = "import_start_disable") == True:
		logging.error("Import execution has been disabled from DBImport configuration")
		import_operation.remove_temporary_files()
		sys.exit(1)


	# ******************************************
	# * IMPORT_PHASE_FULL 
	# ******************************************

	if slaveTable == False and importPhase == constant.IMPORT_PHASE_FULL and runImportPhase == True:
		if stage >= 1000 and stage < 1049 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 1014: newStage = 1011 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()


		# Fetch the source table schema. This is mandatory for all imports
		if runOnlyFunction == None or runOnlyFunction == "getSourceTableSchema":
			if import_operation.runStage(1010) == True: 
				import_operation.getSourceTableSchema()

		if runOnlyFunction == None: 
			if import_operation.runStage(1011) == True: 
				import_operation.clearTableRowCount()

		if runOnlyFunction == None or runOnlyFunction == "getSourceTableRowCount": 
			if import_operation.runStage(1012) == True: 
				import_operation.getJDBCTableRowCount()
	
		if ( runOnlyFunction == None or runOnlyFunction == "sqoop" ) and skipSqoop == False:
			if import_operation.runStage(1013) == True: 
				import_operation.runSqoop(False)

			if import_operation.runStage(1014) == True: 
				import_operation.validateSqoopRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(1049)


	# ******************************************
	# * IMPORT_PHASE_INCR 
	# ******************************************

	if slaveTable == False and importPhase == constant.IMPORT_PHASE_INCR and runImportPhase == True:
		stage = import_operation.getStage()
		if stage >= 1100 and stage < 1149 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			# TODO: Add correct restart points once incremental imports are working
			if stage == 1114: newStage = 1111 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()

		# Fetch the source table schema. This is mandatory for all imports
		if runOnlyFunction == None or runOnlyFunction == "getSourceTableSchema":
			if import_operation.runStage(1110) == True: 
				import_operation.getSourceTableSchema()

		if runOnlyFunction == None: 
			if import_operation.runStage(1111) == True: 
				import_operation.clearTableRowCount()

		if ( runOnlyFunction == None or runOnlyFunction == "sqoop" ) and skipSqoop == False:
			if import_operation.runStage(1112) == True: 
				import_operation.saveIncrMinValue()
				import_operation.runSqoop(False)
				if import_operation.sqoopIncrNoNewRows == True: 
					import_operation.setStage(1149)

		if runOnlyFunction == None or runOnlyFunction == "getSourceTableRowCount": 
			if import_operation.runStage(1113) == True: 
				import_operation.getJDBCTableRowCount()
	
		if runOnlyFunction == None:
			if import_operation.runStage(1114) == True: 
				import_operation.validateSqoopRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(1149)


	# ******************************************
	# * IMPORT_PHASE_ORACLE_FLASHBACK 
	# ******************************************

	if slaveTable == False and importPhase == constant.IMPORT_PHASE_ORACLE_FLASHBACK and runImportPhase == True:
		if stage >= 1200 and stage < 1249 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 1214: newStage = 1211 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()


		# Fetch the source table schema. This is mandatory for all imports
		if runOnlyFunction == None or runOnlyFunction == "getSourceTableSchema":
			if import_operation.runStage(1210) == True: 
				import_operation.getSourceTableSchema()

		if runOnlyFunction == None: 
			if import_operation.runStage(1211) == True: 
				import_operation.clearTableRowCount()

		if ( runOnlyFunction == None or runOnlyFunction == "sqoop" ) and skipSqoop == False:
			if import_operation.runStage(1212) == True: 
				import_operation.runSqoop(False)

		if runOnlyFunction == None or runOnlyFunction == "getSourceTableRowCount": 
			if import_operation.runStage(1213) == True: 
				import_operation.getJDBCTableRowCount()
	
			if import_operation.runStage(1214) == True: 
				import_operation.validateSqoopRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(1249)

	# ******************************************
	# * Copy Phase                                   
	# ******************************************

	if slaveTable == False and copyDestinations != None and runCopyPhase == True:
		# Only run if Import Phase was completed successfully
		stage = import_operation.getStage()
		if stage == 1049 or stage == 1149 or stage == 1249 or stage >= 2000 or runCopyPhaseByForce == True:
			if runOnlyFunction == None or runOnlyFunction == "copyFiles": 
				if import_operation.runStage(2000) == True: 
					copy_operation.copyDataToDestinations()

			if runOnlyFunction == None or runOnlyFunction == "copySchema": 
				if import_operation.runStage(2001) == True: 
					copy_operation.copySchemaToDestinations()

			if runOnlyFunction == None:
				import_operation.setStage(2099)

#	import_operation.remove_temporary_files()
#	sys.exit(1)

	# ******************************************
	# * IMPORT_PHASE_FULL & ETL_PHASE_TRUNCATEINSERT
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_TRUNCATEINSERT and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 3053: newStage = 3050 
			if stage == 3055: newStage = 3054
			if stage == 3056: newStage = 3054
			if stage == 3060: newStage = 3054
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()


		if runImportPhase == False and stage < 1049:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3050) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

			if import_operation.runStage(3051) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3052) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3053) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3054) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3055) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createTargetTable()
				import_operation.updateTargetTable()
				import_operation.addHiveDBImportColumns(mergeOperation=False)
#				import_operation.addDatalakeImportColumn()
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "truncateTargetTable":
			if import_operation.runStage(3056) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.truncateTargetTable()
		
		if runOnlyFunction == None or runOnlyFunction == "loadDataFromImportTable":
			if import_operation.runStage(3057) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.loadDataFromImportToTargetTable()

			if import_operation.runStage(3058) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3059) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3060) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_FULL & ETL_PHASE_INSERT
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_INSERT and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 3103: newStage = 3100 
			if stage == 3109: newStage = 3108
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()


		if runImportPhase == False and stage < 1049:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3100) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

			if import_operation.runStage(3101) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3102) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3103) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3104) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3105) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createTargetTable()
				import_operation.updateTargetTable()
				import_operation.addHiveDBImportColumns(mergeOperation=False)
#				import_operation.addDatalakeImportColumn()
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "loadDataFromImportTable":
			if import_operation.runStage(3106) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.loadDataFromImportToTargetTable()

			if import_operation.runStage(3107) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3108) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3109) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_INCR & ETL_PHASE_INSERT
	# ******************************************
	
	if importPhase == constant.IMPORT_PHASE_INCR and etlPhase == constant.ETL_PHASE_INSERT and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1149 and stage != 2099 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			# TODO: Add correct restart points once incremental imports are working
			if stage == 3153: newStage = 3150 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()

		if runImportPhase == False and stage < 1149:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None:
			if import_operation.import_config.sqoop_last_rows == 0:
				# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
				import_operation.setStage(3160)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3150) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

			if import_operation.runStage(3151) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3152) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3153) == True: 
				import_operation.validateIncrRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3154) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3155) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createTargetTable()
				import_operation.updateTargetTable()
				import_operation.addHiveDBImportColumns(mergeOperation=False)
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "loadDataFromImportTable":
			if import_operation.runStage(3156) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.loadDataFromImportToTargetTable()

			if import_operation.runStage(3157) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3158) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3159) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			if import_operation.runStage(3160) == True: 
				import_operation.saveIncrPendingValues()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_FULL & ETL_PHASE_MERGEHISTORYAUDIT
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_MERGEHISTORYAUDIT and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 3208: newStage = 3200 
			if stage == 3211: newStage = 3204 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()

		if runImportPhase == False and stage < 1049:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3200) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

			if import_operation.runStage(3201) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()
				import_operation.createExternalImportView()
				import_operation.updateExternalImportView()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3202) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3203) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3204) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3205) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createTargetTable()
				import_operation.convertHiveTableToACID()
				import_operation.updateTargetTable()
				import_operation.addHiveDBImportColumns(mergeOperation=True)
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "createHistoryTable":
			if import_operation.runStage(3206) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createHistoryTable()
				import_operation.updateHistoryTable()

		if runOnlyFunction == None or runOnlyFunction == "createDeleteTable":
			if import_operation.runStage(3207) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createDeleteTable()
				import_operation.updateDeleteTable()

		if runOnlyFunction == None or runOnlyFunction == "mergeTable":
			if import_operation.runStage(3208) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				importTableOrView = import_operation.import_config.Hive_Import_Table
				if import_operation.import_config.isExternalViewRequired() == True:
					importTableOrView = import_operation.import_config.Hive_Import_View
				etl_operation.mergeHiveTables(
					sourceDB = import_operation.import_config.Hive_Import_DB, 
					sourceTable = importTableOrView,
					targetDB = import_operation.import_config.Hive_DB, 
					targetTable = import_operation.import_config.Hive_Table, 
					historyDB = import_operation.import_config.Hive_History_DB, 
					historyTable = import_operation.import_config.Hive_History_Table, 
					targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
					targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
					createHistoryAudit = True,
					sourceIsIncremental = False,
					sourceIsImportTable = True,
					softDelete = import_operation.import_config.soft_delete_during_merge, 
					mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
					datalakeSource = import_operation.import_config.datalake_source,
					PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True)
#					hiveMergeJavaHeap = import_operation.import_config.hive_merge_javaheap
				)

			if import_operation.runStage(3209) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3210) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3211) == True: 
				import_operation.validateRowCount()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()


	# ******************************************
	# * IMPORT_PHASE_FULL & ETL_PHASE_MERGEONLY
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_MERGEONLY and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 3260: newStage = 3254 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()

		if runImportPhase == False and stage < 1049:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3250) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

			if import_operation.runStage(3251) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()
				import_operation.createExternalImportView()
				import_operation.updateExternalImportView()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3252) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3253) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3254) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3255) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createTargetTable()
				import_operation.convertHiveTableToACID()
				import_operation.updateTargetTable()
				import_operation.addHiveDBImportColumns(mergeOperation=True)
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "createDeleteTable":
			if import_operation.runStage(3256) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createDeleteTable()
				import_operation.updateDeleteTable()

		if runOnlyFunction == None or runOnlyFunction == "mergeTable":
			if import_operation.runStage(3257) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				importTableOrView = import_operation.import_config.Hive_Import_Table
				if import_operation.import_config.isExternalViewRequired() == True:
					importTableOrView = import_operation.import_config.Hive_Import_View
				etl_operation.mergeHiveTables(
					sourceDB = import_operation.import_config.Hive_Import_DB, 
					sourceTable = importTableOrView,
					targetDB = import_operation.import_config.Hive_DB, 
					targetTable = import_operation.import_config.Hive_Table, 
#					historyDB = import_operation.import_config.Hive_History_DB, 
#					historyTable = import_operation.import_config.Hive_History_Table, 
					targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
					targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
					createHistoryAudit = False,
					sourceIsIncremental = False,
					sourceIsImportTable = True,
					softDelete = import_operation.import_config.soft_delete_during_merge, 
					mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
					datalakeSource = import_operation.import_config.datalake_source,
					PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True)
#					hiveMergeJavaHeap = import_operation.import_config.hive_merge_javaheap
				)

			if import_operation.runStage(3258) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3259) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3260) == True: 
				import_operation.validateRowCount()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_INCR & ETL_PHASE_MERGEONLY
	# ******************************************
	
	if importPhase == constant.IMPORT_PHASE_INCR and etlPhase == constant.ETL_PHASE_MERGEONLY and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1149 and stage != 2099 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			# TODO: Add correct restart points once incremental imports are working
			if stage == 3309: newStage = 3304 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()

		if runImportPhase == False and stage < 1149:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None:
			if import_operation.import_config.sqoop_last_rows == 0:
				# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
				import_operation.setStage(3310)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3300) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

			if import_operation.runStage(3301) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()
				import_operation.createExternalImportView()
				import_operation.updateExternalImportView()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3302) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3303) == True: 
				import_operation.validateIncrRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3304) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3305) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createTargetTable()
				import_operation.addHiveDBImportColumns(mergeOperation=True)
				import_operation.updateTargetTable()
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "mergeTable":
			if import_operation.runStage(3306) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				importTableOrView = import_operation.import_config.Hive_Import_Table
				if import_operation.import_config.isExternalViewRequired() == True:
					importTableOrView = import_operation.import_config.Hive_Import_View
				etl_operation.mergeHiveTables(
					sourceDB = import_operation.import_config.Hive_Import_DB, 
					sourceTable = importTableOrView,
					targetDB = import_operation.import_config.Hive_DB, 
					targetTable = import_operation.import_config.Hive_Table, 
#					historyDB = import_operation.import_config.Hive_History_DB, 
#					historyTable = import_operation.import_config.Hive_History_Table, 
#					targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
#					targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
					createHistoryAudit = False,
					sourceIsIncremental = True,
					sourceIsImportTable = True,
					softDelete = None,
#					softDelete = import_operation.import_config.soft_delete_during_merge, 
					mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
					datalakeSource = import_operation.import_config.datalake_source,
					PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True)
#					hiveMergeJavaHeap = import_operation.import_config.hive_merge_javaheap
				)

			if import_operation.runStage(3307) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3308) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3309) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			if import_operation.runStage(3310) == True: 
				import_operation.saveIncrPendingValues()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_INCR & ETL_PHASE_MERGEHISTORYAUDIT
	# ******************************************
	
	if importPhase == constant.IMPORT_PHASE_INCR and etlPhase == constant.ETL_PHASE_MERGEHISTORYAUDIT and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1149 and stage != 2099 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			# TODO: Add correct restart points once incremental imports are working
			if stage == 3360: newStage = 3354 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()

		if runImportPhase == False and stage < 1149:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None:
			if import_operation.import_config.sqoop_last_rows == 0:
				# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
				import_operation.setStage(3361)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3350) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

			if import_operation.runStage(3351) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()
				import_operation.createExternalImportView()
				import_operation.updateExternalImportView()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3352) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3353) == True: 
				import_operation.validateIncrRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3354) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3355) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createTargetTable()
				import_operation.updateTargetTable()
				import_operation.addHiveDBImportColumns(mergeOperation=True)
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "createHistoryTable":
			if import_operation.runStage(3356) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createHistoryTable()
				import_operation.updateHistoryTable()

		if runOnlyFunction == None or runOnlyFunction == "mergeTable":
			if import_operation.runStage(3357) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				importTableOrView = import_operation.import_config.Hive_Import_Table
				if import_operation.import_config.isExternalViewRequired() == True:
					importTableOrView = import_operation.import_config.Hive_Import_View
				etl_operation.mergeHiveTables(
					sourceDB = import_operation.import_config.Hive_Import_DB, 
					sourceTable = importTableOrView,
					targetDB = import_operation.import_config.Hive_DB, 
					targetTable = import_operation.import_config.Hive_Table, 
					historyDB = import_operation.import_config.Hive_History_DB, 
					historyTable = import_operation.import_config.Hive_History_Table, 
#					targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
#					targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
					createHistoryAudit = True,
					sourceIsIncremental = True,
					sourceIsImportTable = True,
					softDelete = None,
#					softDelete = import_operation.import_config.soft_delete_during_merge, 
					mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
					datalakeSource = import_operation.import_config.datalake_source,
					PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True)
#					hiveMergeJavaHeap = import_operation.import_config.hive_merge_javaheap
				)

			if import_operation.runStage(3358) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3359) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3360) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			if import_operation.runStage(3361) == True: 
				import_operation.saveIncrPendingValues()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# *******************************************************
	# * IMPORT_PHASE_ORACLE_FLASHBACK & ETL_PHASE_MERGEONLY
	# *******************************************************
	
	if importPhase == constant.IMPORT_PHASE_ORACLE_FLASHBACK and etlPhase == constant.ETL_PHASE_MERGEONLY and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1249 and stage != 2099 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			# TODO: Add correct restart points once incremental imports are working
			if stage == 3409: newStage = 3404 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()

		if runImportPhase == False and stage < 1249:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None:
			if import_operation.import_config.sqoop_last_rows == 0:
				# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
				import_operation.setStage(3410)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3400) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

			if import_operation.runStage(3401) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()
				import_operation.createExternalImportView()
				import_operation.updateExternalImportView()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3402) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3403) == True: 
				import_operation.validateIncrRowCount()
				import_operation.getImportViewRowCountAsSource(incr=True)

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3404) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3405) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createTargetTable()
				import_operation.updateTargetTable()
				import_operation.addHiveDBImportColumns(mergeOperation=True)
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "mergeTable":
			if import_operation.runStage(3406) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.import_config.isExternalViewRequired() == True:
					importTableOrView = import_operation.import_config.Hive_Import_View
				else:
					importTableOrView = import_operation.import_config.Hive_Import_Table

				if import_operation.import_config.incr_maxvalue == None: 
					# If it's an initial or reinitialized load, we need to remove old lines from target table
					deleteNotUpdatedRows = True
				else:
					deleteNotUpdatedRows = False

				etl_operation.mergeHiveTables(
					sourceDB = import_operation.import_config.Hive_Import_DB, 
					sourceTable = importTableOrView,
					targetDB = import_operation.import_config.Hive_DB, 
					targetTable = import_operation.import_config.Hive_Table, 
#					historyDB = import_operation.import_config.Hive_History_DB, 
#					historyTable = import_operation.import_config.Hive_History_Table, 
#					targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
#					targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
					createHistoryAudit = False,
					sourceIsIncremental = True,
					sourceIsImportTable = True,
					oracleFlashbackSource = True,
					softDelete = None,
#					softDelete = import_operation.import_config.soft_delete_during_merge, 
					mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
					datalakeSource = import_operation.import_config.datalake_source,
					PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True),
#					hiveMergeJavaHeap = import_operation.import_config.hive_merge_javaheap,
					deleteNotUpdatedRows = deleteNotUpdatedRows
				)

			if import_operation.runStage(3407) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3408) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3409) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			if import_operation.runStage(3410) == True: 
				import_operation.saveIncrPendingValues()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_FULL & ETL_PHASE_NONE
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_NONE and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 3453: newStage = 3450 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")
			sys.stdout.flush()


		if runImportPhase == False and stage < 1049:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3450) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)

			if import_operation.runStage(3451) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3452) == True: 
				import_operation.connectToHive(forceSkipTest=skipHiveTest)
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3453) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * Print Import information
	# ******************************************

	if import_operation.getStage() == 9999: 
		if runOnlyFunction == None:
			if runImportPhase == True and runETLPhase == False:
				print(" ___________________________________ ")
				print("|                                   |")
				print("| Import Phase completed successful |") 	
				print("|___________________________________|")
			elif runImportPhase == False and runETLPhase == True:
				print(" ________________________________ ")
				print("|                                |")
				print("| ETL Phase completed successful |") 	
				print("|________________________________|")
			else:
				print(" _____________________________ ")
				print("|                             |")
				print("| Import completed successful |") 	
				print("|_____________________________|")
			print("")

			if runETLPhase == True:
				# We can only clear the stage at the end of stage 2. 
				import_operation.clearStage()

	import_operation.remove_temporary_files()

if __name__ == "__main__":
	main(sys.argv[1:])

