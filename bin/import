#!/usr/bin/env python3
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import os
import sys
import getopt
import logging
from common import constants as constant
from common.Exceptions import *
from DBImportOperation import import_operations
from DBImportOperation import copy_operations
from DBImportOperation import etl_operations

def printHelp():
	print ("Options:")
	print ("  --help             Show this help message and exit")
	print ("  -v, --debug        Turn on extensive debug output. This will print passwords in cleartext, so use with caution")
	print ("  -V, --version      Displays the version of DBImport")
	print ("  --skipImportData   Dont run the import data command. Useful when the files are correct and you need to recreate Hive tables")
	print ("  --ignoreTime       Ignores the start and stop time for the table. Will run outside that window regardless")
	print ("  --resetStage       Starts from the beginning regardless of previous problems")
	print ("  -h [Hive Database], --Hive_DB=[Hive Database]")
	print ("                     Hive database")
	print ("  -t [Hive Table], --Hive_Table=[Hive Table]")
	print ("                     Hive table")
	print ("  -I, -1             Only run functions in Import Phase. ")
	print ("  -C                 Only run functions in Copy Phase. ")
	print ("  -E, -2             Only run functions in ETL Phase.")
	print ("  -m, --metaDataOnly Only import metaData regarding columns, constraints and number of rows from source system")
	print ("  -f [Function], --function=[Function]")
	print ("                     Only run the specified function. This is used for debugging and when migrating from")
	print ("                     bash based DBImport scripts. Using a function ignore what ever stage the import is in.")
	print ("                     Use with caution!")
	print ("                     Valid function options are:")
	print ("                     - getSourceTableSchema")
	print ("                     - updateAtlas")
	print ("                     - importData")
	print ("                     - createImportTable")
	print ("                     - getSourceTableRowCount")
	print ("                     - getImportTableRowCount")
	print ("                     - getTargetTableRowCount")
	print ("                     - createTargetTable")
	print ("                     - createHistoryTable")
	print ("                     - createDeleteTable")
	print ("                     - removeHiveLocks")
	print ("                     - truncateTargetTable")
	print ("                     - loadDataFromImportTable")
	print ("                     - mergeTable")
	print ("                     - createStatistics")
	print ("                     - copySchema")
	print ("                     - copyFiles")
	print ("                     - compaction")
	sys.exit(1)
	
def printBox(messageList):
	# This code is not completed. It was a way to easily create the Ascii boxes used in the import, but we are still using hard-coded boxes. One day.....
	if type(messageList) is not list:
		messageList = [messageList]

	startLine = ""
	stopLine = ""
	maxLength = 0
	for message in messageList:
		if len(message) > maxLength:
			maxLength = len(message)

	for i in range(maxLength):
		startLine += "_"
		stopLine += "_"

	print(startLine)
	for message in messageList:
		if len(message) > maxLength:
			maxLength = len(message)
	print(stopLine)

def main(argv):

	try:
		opts, args = getopt.getopt(argv, "mvVICE12f:h:t:", ["version", "help", "function=", "Hive_DB=", "Hive_Table=", "debug", "skipImportData", "skipSqoop", "ignoreTime", "resetStage", "skipHiveTest", "metaDataOnly", "ignoreDisabled"])
	except getopt.GetoptError:
		printHelp()

	fullExecutedCommand = "%s %s"%(os.path.basename(__file__), " ".join(argv))
	Hive_DB = None
	Hive_Table = None
	runOnlyFunction = None
	loggingLevel = logging.INFO
	skipImportData = False
	runImportPhase = False
	runCopyPhase = False
	runCopyPhaseByForce = False
	runETLPhase = False
	displayVersion = False
	ignoreTime = False
	resetStage = False
	skipHiveTest = False
	metaDataOnlyImport = False
	ignoreDisabled = False

	if  len(opts) == 0:
		printHelp()

	for opt, arg in opts:
		if opt in ("-h", "--Hive_DB"):
			Hive_DB = arg
		elif opt in ("-t", "--Hive_Table"):
			Hive_Table = arg
		elif opt in ("-v", "--debug"):
			loggingLevel = logging.DEBUG
		elif opt in ("-V", "--version"):
			displayVersion = True
		elif opt == "--skipSqoop":
			skipImportData = True
		elif opt == "--skipImportData":
			skipImportData = True
		elif opt == "--skipHiveTest":
			skipHiveTest = True
		elif opt == "--resetStage":
			resetStage = True
		elif opt == "--ignoreTime":
			ignoreTime = True
		elif opt in ("-f", "--function"):
			runOnlyFunction = arg
		elif opt in ("-m", "--metaDataOnly"):
			metaDataOnlyImport = True
			runOnlyFunction = "metaDataOnly"
		elif opt == "--help":
			printHelp()
		elif opt == "-1":
			runImportPhase = True
		elif opt == "-2":
			runETLPhase = True
		elif opt == "-I":
			runImportPhase = True
		elif opt == "-C":
			runCopyPhase = True
		elif opt == "-E":
			runETLPhase = True
		elif opt == "--ignoreDisabled":
			ignoreDisabled = True

	if displayVersion == True:
		print("DBImport version: %s"%(constant.VERSION))
		sys.exit(0)

	if Hive_DB == None or Hive_Table == None:
		printHelp()

	if runImportPhase == False and runETLPhase == False and runCopyPhase == False:
		# If nothing is specified we run all stages
		runImportPhase = True
		runCopyPhase = True
		runETLPhase = True

	if runOnlyFunction != None:
		if runOnlyFunction not in ("getSourceTableSchema", "onlyMain", "sqoop", "importData", "createImportTable", "getImportTableRowCount", "getTargetTableRowCount", "createTargetTable", "removeHiveLocks", "truncateTargetTable", "loadDataFromImportTable", "createStatistics", "getSourceTableRowCount", "mergeTable", "createHistoryTable", "createDeleteTable", "copySchema", "copyFiles", "updateAtlas", "compaction", "metaDataOnly"):
			printHelp()

	# Initiate the logging functions with the correct level
	if loggingLevel == logging.DEBUG:
		logging.basicConfig(format='%(levelname)s %(funcName)s - %(message)s', level=loggingLevel)
	else:
		logging.basicConfig(format='%(levelname)s - %(message)s', level=loggingLevel)

	# Font created at http://patorjk.com/software/taag/#p=display&f=Big&t=DBImport%20-%20Import
	sys.stdout.write(u"\u001b[35m")  # Magenta
	sys.stdout.flush()
	print("")
	print(" _____  ____ _____                            _              _____                            _   ")
	print("|  __ \|  _ \_   _|                          | |            |_   _|                          | |  ")
	print("| |  | | |_) || |  _ __ ___  _ __   ___  _ __| |_   ______    | |  _ __ ___  _ __   ___  _ __| |_ ")
	print("| |  | |  _ < | | | '_ ` _ \| '_ \ / _ \| '__| __| |______|   | | | '_ ` _ \| '_ \ / _ \| '__| __|")
	print("| |__| | |_) || |_| | | | | | |_) | (_) | |  | |_            _| |_| | | | | | |_) | (_) | |  | |_ ")
	print("|_____/|____/_____|_| |_| |_| .__/ \___/|_|   \__|          |_____|_| |_| |_| .__/ \___/|_|   \__|")
	print("                            | |                                             | |                   ")
	print("                            |_|                                             |_|                   ")
	sys.stdout.write(u"\u001b[0m")  # Reset
	sys.stdout.flush()
	print("")
	print("Version: %s"%(constant.VERSION))
	print("")
	print("")
	
	import_operation = None
	try:
		# Initiate the master class for all import operations
		import_operation = import_operations.operation(Hive_DB, Hive_Table)
		copy_operation = copy_operations.operation()
		etl_operation = etl_operations.operation()
	except KeyboardInterrupt:
		logging.error("Program exit because requested by user.")
		if import_operation != None:
			import_operation.import_config.remove_temporary_files()
		sys.exit(1)
	except invalidConfiguration as errMsg:
		logging.error(errMsg)
		if import_operation != None:
			import_operation.import_config.remove_temporary_files()
		sys.exit(1)
	except daemonExit as errMsg:
		logging.error("Program exit because requested to do so by developer. %s"%(errMsg))
		if import_operation != None:
			import_operation.import_config.remove_temporary_files()
		sys.exit(1)
	except FileExistsError:
		sys.exit(1)
	except:
		if import_operation != None:
			import_operation.import_config.remove_temporary_files()
		raise
		sys.exit(1)

	processEmptyTables = import_operation.import_config.common_config.getConfigValue(key = "import_process_empty")

	copyDestinations = copy_operation.getCopyDestinations(hiveDB = Hive_DB, hiveTable = Hive_Table)

	# Save data down to import_operation
	import_operation.import_config.fullExecutedCommand = fullExecutedCommand

	# Get the name of the different phases we are going to execute
	importPhase = import_operation.import_config.importPhase 
	etlPhase    = import_operation.import_config.etlPhase 
	importPhaseDescription = import_operation.import_config.importPhaseDescription 
	etlPhaseDescription    = import_operation.import_config.etlPhaseDescription 

	slaveTable = import_operation.import_config.copy_slave

	print("The following table will be imported")
	print("______________________________________________________________________________")
	print("")
	if import_operation.import_config.import_type != None and import_operation.import_config.import_type != "":
		print("Import Type (OLD):        %s"%(import_operation.import_config.import_type))
		print("Import description (OLD): %s"%(import_operation.import_config.import_type_description))
	print("Import Phase:             %s"%(importPhaseDescription))

	if copyDestinations == None:
		print("Copy destinations:        No cluster copy")
	else:
		firstRow = True
		for dest in copyDestinations:
			if firstRow == True:
				print("Copy destinations:        %s"%(dest.replace(';', " - ")))
				firstRow = False
			else:
				print("                          %s"%(dest.replace(';', " - ")))

	print("ETL Phase:                %s"%(etlPhaseDescription))
	print("Import Tool:              %s"%(import_operation.import_config.importTool))
	print("JDBC Connection name:     %s"%(import_operation.import_config.common_config.dbAlias))
	print("Source hostname:          %s"%(import_operation.import_config.common_config.jdbc_hostname))
	print("Source database type:     %s"%(import_operation.import_config.common_config.jdbc_servertype))
	print("Source database:          %s"%(import_operation.import_config.common_config.jdbc_database))
	if import_operation.import_config.source_schema != "-":
		print("Source schema:            %s"%(import_operation.import_config.source_schema))
	print("Source table:             %s"%(import_operation.import_config.source_table))
	print("Hive database:            %s"%(import_operation.import_config.Hive_DB))
	print("Hive table:               %s"%(import_operation.import_config.Hive_Table))
	print("______________________________________________________________________________")
	print("")
	sys.stdout.flush()

	# To handle backward combability. 
	if runOnlyFunction == "sqoop":
		logging.warning("runOnlyFunction 'sqoop' is deprecated. Please use 'importData' instead.")
		runOnlyFunction = "importData"

	if runOnlyFunction != None:
		print(" _______________________________________________________ ")
		print("|                                                       |")
		print("| This is not a full import as a function was specified |") 	
		print("|_______________________________________________________|")
		print("")
		print("")
		import_operation.setStageOnlyInMemory()

	stage = import_operation.getStage()

	# Check if the configured Hive database exists
	import_operation.checkHiveDB(Hive_DB.lower())

	if import_operation.import_config.common_config.checkKerberosTicket() == False:
		logging.error("There is no valid Kerberos ticket available. Please create one before running this command")
		import_operation.remove_temporary_files()
		sys.exit(1)

	if resetStage == True or stage == 9999:
		import_operation.setStage(0, force=True)
		stage = 0

	if stage == 0:
		# This means it's the first attempt (or a reset) of this import. So we can send the start message to Kafka or REST in this case
#		import_operation.convertStageStatisticsToJSON()
		import_operation.sendStartJSON()

	if copy_operation.isPreviousCopyCompleted() == False and stage < 2099 :
		logging.error("There is a previous copy that isnt completed yet. This import cant continue until that copy is completed") 
		import_operation.remove_temporary_files()
		sys.exit(1)

	if ignoreTime == False and runImportPhase == True and stage < 2000 and slaveTable == False:
		# Checking if we are allowed to use the configued JDBC connection at this time
		# We only need to check this if we are going to run the Import stage and the stage is under the copyPhase. 
		# So if the previous import failed, and it's only the ETL part left, we should still be able to finish the import
		import_operation.checkTimeWindow()


	if ( runImportPhase == True and runETLPhase == False and runCopyPhase == False ) and runOnlyFunction == None:
		print(" _____________________ ")
		print("|                     |")
		print("| Import Phase only   |")
		print("|_____________________|")
		print("")
		print("")
		if stage > 1999:
			print("Warning: There is already an ongoing import with a stage that already passed the Import stage. Nothing will happen")

	if ( runImportPhase == False and runETLPhase == False  and runCopyPhase == True) and runOnlyFunction == None:
		print(" ___________________")
		print("|                   |")
		print("| Copy Phase only   |")
		print("|___________________|")
		print("")
		print("")
		if stage > 2999:
			print("Warning: There is already an ongoing import with a stage that already passed the Copy stage. Nothing will happen")
		if stage < 2000 and stage != 1049 and stage != 1149 and stage != 1249 and stage != 0:
			print("Warning: There is already an ongoing import but it havent completed the Import stage yet. Nothing will happen")

		# As we can run copy phase only, we will just keep the stage info in memories for these imports
		if stage == 0:
			import_operation.setStageOnlyInMemory()
			runCopyPhaseByForce = True

	if ( runImportPhase == False and runETLPhase == True  and runCopyPhase == False) and runOnlyFunction == None:
		print(" __________________")
		print("|                  |")
		print("| ETL Phase only   |")
		print("|__________________|")
		print("")
		print("")

	if stage > 0 and stage < 1000:
		# TODO: Remove this once everything is migrated to python version
		print(" ________________________________________________________ ")
		print("|                                                        |")
		print("| ERROR: Stage information incorrect. Did you run the    |") 	
		print("|        python version of DBImport last time?           |") 	
		print("|________________________________________________________|")
		print("")
		print("")
		import_operation.remove_temporary_files()
		sys.exit(1)

	if runImportPhase == True and runETLPhase == False and ( stage == 1049 or stage == 1149 ):
		print(" ______________________________________ ")
		print("|                                      |")
		print("| Import Phase is already completed.   |") 
		print("| To continue, run with option '-2'    |") 	
		print("|______________________________________|")

		import_operation.remove_temporary_files()
		sys.exit(0)

	sys.stdout.flush()


	if import_operation.import_config.common_config.getConfigValue(key = "import_start_disable") == True and ignoreDisabled == False:
		logging.error("Import execution has been disabled from DBImport configuration")
		import_operation.remove_temporary_files()
		sys.exit(1)


	try:

		# ******************************************
		# * IMPORT_PHASE_FULL 
		# ******************************************

		if slaveTable == False and importPhase == constant.IMPORT_PHASE_FULL and runImportPhase == True:
			if stage >= 1000 and stage < 1049 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)
	
				newStage = 0
				if stage == 1020: newStage = 1011 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			# Fetch the source table schema. This is mandatory for all imports
			if runOnlyFunction == None or runOnlyFunction in ("getSourceTableSchema", "metaDataOnly"):
				if import_operation.runStage(1010) == True: 
					import_operation.getSourceTableSchema()

			if runOnlyFunction == None: 
				if import_operation.runStage(1011) == True: 
					import_operation.clearValidationData()

			if runOnlyFunction == None or runOnlyFunction in ("getSourceTableRowCount", "metaDataOnly"): 
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(1012) == True: 
						import_operation.getJDBCTableValidationData()
	
			if ( runOnlyFunction == None or runOnlyFunction == "importData" ) and skipImportData == False:
				if import_operation.import_config.importTool == "sqoop": 
					if import_operation.runStage(1013) == True:
						import_operation.runSqoopImport(False)
				if import_operation.import_config.importTool == "spark": 
					if import_operation.runStage(1014) == True:
						import_operation.runSparkImport(False)

				if import_operation.runStage(1020) == True: 
					import_operation.validateImportTool()

			if runOnlyFunction == None or runOnlyFunction == "updateAtlas": 
				if import_operation.runStage(1045) == True: 
					import_operation.updateAtlasWithImportData()
#					import_operation.updateAtlasWithSourceSchema()
#					import_operation.updateAtlasWithImportLineage()
	
			if runOnlyFunction == None:
				import_operation.setStage(1049)

		# ******************************************
		# * IMPORT_PHASE_INCR 
		# ******************************************

		if slaveTable == False and importPhase == constant.IMPORT_PHASE_INCR and runImportPhase == True:
			stage = import_operation.getStage()
			if stage >= 1100 and stage < 1149 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				# TODO: Add correct restart points once incremental imports are working
				if stage == 1121: newStage = 1111 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			# Fetch the source table schema. This is mandatory for all imports
			if runOnlyFunction == None or runOnlyFunction in ("getSourceTableSchema", "metaDataOnly"):
				if import_operation.runStage(1110) == True: 
					import_operation.getSourceTableSchema()

			if runOnlyFunction == None: 
				if import_operation.runStage(1111) == True: 
					import_operation.clearValidationData()

			if ( runOnlyFunction == None or runOnlyFunction == "importData" ) and skipImportData == False:
				if import_operation.import_config.importTool == "sqoop": 
					if import_operation.runStage(1112) == True: 
						import_operation.saveIncrMinValue()
						import_operation.runSqoopImport(False)
						if import_operation.sqoopIncrNoNewRows == True: 
							import_operation.setStage(1149)
				if import_operation.import_config.importTool == "spark": 
					if import_operation.runStage(1113) == True: 
						import_operation.saveIncrMinValue()
						import_operation.runSparkImport(False)
						if import_operation.sqoopIncrNoNewRows == True: 
							import_operation.setStage(1149)

			if runOnlyFunction == None or runOnlyFunction in ("getSourceTableRowCount", "metaDataOnly"):
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(1120) == True: 
						if runOnlyFunction == "metaDataOnly":
							logging.warning("MetaDataOnly imports only supports rowcount information during full/truncate_insert import") 
						else:
							import_operation.getJDBCTableValidationData()
	
			if runOnlyFunction == None:
				if import_operation.runStage(1121) == True: 
					import_operation.validateImportTool()

			if runOnlyFunction == None or runOnlyFunction == "updateAtlas": 
				if import_operation.runStage(1145) == True: 
					import_operation.updateAtlasWithImportData()
#					import_operation.updateAtlasWithSourceSchema()
#					import_operation.updateAtlasWithImportLineage()
	
			if runOnlyFunction == None:
				import_operation.setStage(1149)


		# ******************************************
		# * IMPORT_PHASE_ORACLE_FLASHBACK 
		# ******************************************

		if slaveTable == False and importPhase == constant.IMPORT_PHASE_ORACLE_FLASHBACK and runImportPhase == True:
			if stage >= 1200 and stage < 1249 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				if stage == 1221: newStage = 1211 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			# Fetch the source table schema. This is mandatory for all imports
			if runOnlyFunction == None or runOnlyFunction in ("getSourceTableSchema", "metaDataOnly"):
				if import_operation.runStage(1210) == True: 
					import_operation.getSourceTableSchema()

			if runOnlyFunction == None: 
				if import_operation.runStage(1211) == True: 
					import_operation.clearValidationData()

			if runOnlyFunction == None: 
				if import_operation.runStage(1211) == True: 
					# This will force an initial load if the SCN number is to old
					import_operation.checkOracleFlashbackSCNnumber()

#			import_operation.setStage(9000)

			if ( runOnlyFunction == None or runOnlyFunction == "importData" ) and skipImportData == False:
				if import_operation.import_config.importTool == "sqoop": 
					if import_operation.runStage(1215) == True:
						import_operation.runSqoopImport(False)
				if import_operation.import_config.importTool == "spark": 
					if import_operation.runStage(1216) == True:
						import_operation.runSparkImport(False)

			if runOnlyFunction == None or runOnlyFunction in ("getSourceTableRowCount", "metaDataOnly"):
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(1220) == True: 
						if runOnlyFunction == "metaDataOnly":
							logging.warning("MetaDataOnly imports only supports rowcount information during full/truncate_insert import") 
						else:
							import_operation.getJDBCTableValidationData()
	
				if import_operation.runStage(1221) == True: 
					if runOnlyFunction != "metaDataOnly":
						import_operation.validateImportTool()
	
			if runOnlyFunction == None or runOnlyFunction == "updateAtlas": 
				if import_operation.runStage(1245) == True: 
					import_operation.updateAtlasWithImportData()
#					import_operation.updateAtlasWithSourceSchema()
#					import_operation.updateAtlasWithImportLineage()
	
			if runOnlyFunction == None:
				import_operation.setStage(1249)

		# ******************************************
		# * IMPORT_PHASE_MSSQL_CHANGE_TRACKING 
		# ******************************************

		if slaveTable == False and importPhase == constant.IMPORT_PHASE_MSSQL_CHANGE_TRACKING and runImportPhase == True:
			if stage >= 1250 and stage < 1299 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				if stage == 1265: newStage = 1261 
				if stage == 1271: newStage = 1261 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			# Fetch the source table schema. This is mandatory for all imports
			if runOnlyFunction == None or runOnlyFunction in ("getSourceTableSchema", "metaDataOnly"):
				if import_operation.runStage(1260) == True: 
					import_operation.getSourceTableSchema()

			if runOnlyFunction == None: 
				if import_operation.runStage(1261) == True: 
					import_operation.clearValidationData()

			if runOnlyFunction == None: 
				if import_operation.runStage(1262) == True: 
					import_operation.import_config.checkMSSQLChangeTrackingMinValidVersion()

			if ( runOnlyFunction == None or runOnlyFunction == "importData" ) and skipImportData == False:
#				if import_operation.import_config.importTool == "sqoop": 
#					if import_operation.runStage(1264) == True:
#						import_operation.runSqoopImport(False)
				if import_operation.import_config.importTool == "spark": 
					if import_operation.runStage(1265) == True:
						import_operation.runSparkImport(False)

			if runOnlyFunction == None or runOnlyFunction in ("getSourceTableRowCount", "metaDataOnly"):
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(1270) == True: 
						if runOnlyFunction == "metaDataOnly":
							logging.warning("MetaDataOnly imports only supports rowcount information during full/truncate_insert import") 
						else:
							import_operation.getJDBCTableValidationData()
	
#				if import_operation.runStage(1271) == True: 
#					import_operation.validateImportTool()
	
			if runOnlyFunction == None or runOnlyFunction == "updateAtlas": 
				if import_operation.runStage(1295) == True: 
					import_operation.updateAtlasWithImportData()
	
			if runOnlyFunction == None:
				import_operation.setStage(1299)

		# ******************************************
		# * IMPORT_PHASE_MONGO_FULL
		# ******************************************

		if slaveTable == False and importPhase == constant.IMPORT_PHASE_MONGO_FULL and runImportPhase == True:
			if stage >= 1300 and stage < 1349 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
#				if stage == 1221: newStage = 1211 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			if runOnlyFunction == "metaDataOnly":
				logging.error("MetaDataOnly imports is not supported for Mongo databases")
				import_operation.import_config.remove_temporary_files()
				sys.exit(1)

			if runOnlyFunction == None: 
				if import_operation.runStage(1310) == True: 
					import_operation.clearValidationData()

			if ( runOnlyFunction == None or runOnlyFunction == "importData" ) and skipImportData == False:
				if import_operation.runStage(1315) == True:
					import_operation.runSparkImportForMongo()

			if runOnlyFunction == None or runOnlyFunction == "getSourceTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.import_config.validate_import == True:
						if import_operation.runStage(1320) == True: 
							import_operation.getMongoRowCount()
	
			if import_operation.runStage(1325) == True: 
				import_operation.validateSqoopRowCount()

			if runOnlyFunction == None:
				import_operation.setStage(1349)

		# ******************************************
		# * Copy Phase                                   
		# ******************************************


		if slaveTable == False and copyDestinations != None and runCopyPhase == True:
			# Only run if Import Phase was completed successfully
			stage = import_operation.getStage()
			if stage == 1049 or stage == 1149 or stage == 1249 or stage >= 2000 or runCopyPhaseByForce == True:
				if runOnlyFunction == None or runOnlyFunction == "copyFiles": 
					if import_operation.runStage(2001) == True: 
						copy_operation.copyDataToDestinations()

				if runOnlyFunction == None or runOnlyFunction == "copySchema": 
					if import_operation.runStage(2002) == True: 
						copy_operation.copyImportSchemaToDestinations()

				if runOnlyFunction == None:
					import_operation.setStage(2099)


		# ******************************************
		# * IMPORT_PHASE_FULL & ETL_PHASE_TRUNCATEINSERT
		# ******************************************

		if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_TRUNCATEINSERT and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				if stage == 3053: newStage = 3050 
				if stage == 3055: newStage = 3054
				if stage == 3056: newStage = 3054
				if stage == 3060: newStage = 3054
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()


			if runImportPhase == False and stage < 1049:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3050) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3051) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.runStage(3052) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.getImportTableValidationData()

				if import_operation.runStage(3053) == True: 
					import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3054) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3055) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=False)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "truncateTargetTable":
				if import_operation.runStage(3056) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.truncateTargetTable()
		
			if runOnlyFunction == None or runOnlyFunction == "loadDataFromImportTable":
				if import_operation.runStage(3057) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.loadDataFromImportToTargetTable()

				if import_operation.runStage(3058) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3059) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3060) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# ******************************************
		# * IMPORT_PHASE_FULL & ETL_PHASE_INSERT
		# ******************************************

		if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_INSERT and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				if stage == 3103: newStage = 3100 
				if stage == 3109: newStage = 3108
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()


			if runImportPhase == False and stage < 1049:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3100) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3101) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3102) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3103) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3104) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3105) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=False)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "loadDataFromImportTable":
				if import_operation.runStage(3106) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.loadDataFromImportToTargetTable()

				if import_operation.runStage(3107) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3108) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3109) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# ******************************************
		# * IMPORT_PHASE_INCR & ETL_PHASE_INSERT
		# ******************************************
	
		if importPhase == constant.IMPORT_PHASE_INCR and etlPhase == constant.ETL_PHASE_INSERT and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1149 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				# TODO: Add correct restart points once incremental imports are working
				if stage == 3153: newStage = 3150 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			if runImportPhase == False and stage < 1149:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None:
				if import_operation.import_config.sqoop_last_rows == 0 and processEmptyTables == False:
					logging.info("No new rows have been imported. The ETL stage will be skipped")
					# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
					import_operation.setStage(3160)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3150) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3151) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3152) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3153) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3154) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3155) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=False)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "loadDataFromImportTable":
				if import_operation.runStage(3156) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.loadDataFromImportToTargetTable()

				if import_operation.runStage(3157) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3158) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3159) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				if import_operation.runStage(3160) == True: 
					import_operation.saveIncrPendingValues()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# ******************************************
		# * IMPORT_PHASE_FULL & ETL_PHASE_MERGEHISTORYAUDIT
		# ******************************************

		if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_MERGEHISTORYAUDIT and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				if stage == 3208: newStage = 3200 
				if stage == 3211: newStage = 3204 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			if runImportPhase == False and stage < 1049:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3200) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3201) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()
					import_operation.createExternalImportView()
					import_operation.updateExternalImportView()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3202) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3203) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3204) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3205) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.convertHiveTableToACID()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=True)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "createHistoryTable":
				if import_operation.runStage(3206) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createHistoryTable()
					import_operation.updateHistoryTable()

			if runOnlyFunction == None or runOnlyFunction == "createDeleteTable":
				if import_operation.runStage(3207) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createDeleteTable()
					import_operation.updateDeleteTable()

			if runOnlyFunction == None or runOnlyFunction == "mergeTable":
				if import_operation.runStage(3208) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					importTableOrView = import_operation.import_config.Hive_Import_Table
					if import_operation.import_config.isExternalViewRequired() == True:
						importTableOrView = import_operation.import_config.Hive_Import_View
					etl_operation.mergeHiveTables(
						sourceDB = import_operation.import_config.Hive_Import_DB, 
						sourceTable = importTableOrView,
						targetDB = import_operation.import_config.Hive_DB, 
						targetTable = import_operation.import_config.Hive_Table, 
						historyDB = import_operation.import_config.Hive_History_DB, 
						historyTable = import_operation.import_config.Hive_History_Table, 
						targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
						targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
						createHistoryAudit = True,
						sourceIsIncremental = False,
						sourceIsImportTable = True,
						softDelete = import_operation.import_config.soft_delete_during_merge, 
						mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
						datalakeSource = import_operation.import_config.datalake_source,
						PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True)
					)

				if import_operation.runStage(3209) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3210) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3211) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "compaction":
				if import_operation.runStage(3212) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.runHiveCompaction()
#					import_operation.runHiveMajorCompaction()

			if runOnlyFunction == None:
				import_operation.setStage(9999)
	
			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()


		# ******************************************
		# * IMPORT_PHASE_FULL & ETL_PHASE_MERGEONLY
		# ******************************************

		if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_MERGEONLY and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				if stage == 3260: newStage = 3254 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			if runImportPhase == False and stage < 1049:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3250) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3251) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()
					import_operation.createExternalImportView()
					import_operation.updateExternalImportView()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3252) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3253) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3254) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3255) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.convertHiveTableToACID()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=True)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "createDeleteTable":
				if import_operation.runStage(3256) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createDeleteTable()
					import_operation.updateDeleteTable()

			if runOnlyFunction == None or runOnlyFunction == "mergeTable":
				if import_operation.runStage(3257) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					importTableOrView = import_operation.import_config.Hive_Import_Table
					if import_operation.import_config.isExternalViewRequired() == True:
						importTableOrView = import_operation.import_config.Hive_Import_View
					etl_operation.mergeHiveTables(
						sourceDB = import_operation.import_config.Hive_Import_DB, 
						sourceTable = importTableOrView,
						targetDB = import_operation.import_config.Hive_DB, 
						targetTable = import_operation.import_config.Hive_Table, 
						targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
						targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
						createHistoryAudit = False,
						sourceIsIncremental = False,
						sourceIsImportTable = True,
						softDelete = import_operation.import_config.soft_delete_during_merge, 
						mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
						datalakeSource = import_operation.import_config.datalake_source,
						PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True)
					)

				if import_operation.runStage(3258) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3259) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3260) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "compaction":
				if import_operation.runStage(3261) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.runHiveCompaction()
#					import_operation.runHiveMajorCompaction()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# ******************************************
		# * IMPORT_PHASE_INCR & ETL_PHASE_MERGEONLY
		# ******************************************
	
		if importPhase == constant.IMPORT_PHASE_INCR and etlPhase == constant.ETL_PHASE_MERGEONLY and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1149 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				# TODO: Add correct restart points once incremental imports are working
				if stage == 3303: newStage = 3302
				if stage == 3306: newStage = 3304
				if stage == 3309: newStage = 3304 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			if runImportPhase == False and stage < 1149:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None:
				if import_operation.import_config.sqoop_last_rows == 0 and processEmptyTables == False:
					logging.info("No new rows have been imported. The ETL stage will be skipped")
					# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
					import_operation.setStage(3310)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3300) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3301) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()
					import_operation.createExternalImportView()
					import_operation.updateExternalImportView()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3302) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3303) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3304) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3305) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.convertHiveTableToACID()
					import_operation.addHiveDBImportColumns(mergeOperation=True)
					import_operation.updateTargetTable()
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "mergeTable":
				if import_operation.runStage(3306) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					importTableOrView = import_operation.import_config.Hive_Import_Table
					if import_operation.import_config.isExternalViewRequired() == True:
						importTableOrView = import_operation.import_config.Hive_Import_View
					etl_operation.mergeHiveTables(
						sourceDB = import_operation.import_config.Hive_Import_DB, 
						sourceTable = importTableOrView,
						targetDB = import_operation.import_config.Hive_DB, 
						targetTable = import_operation.import_config.Hive_Table, 
						createHistoryAudit = False,
						sourceIsIncremental = True,
						sourceIsImportTable = True,
						softDelete = None,
						mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
						datalakeSource = import_operation.import_config.datalake_source,
						PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True)
					)

				if import_operation.runStage(3307) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3308) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3309) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				if import_operation.runStage(3310) == True: 
					import_operation.saveIncrPendingValues()

			if runOnlyFunction == None or runOnlyFunction == "compaction":
				if import_operation.runStage(3311) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.runHiveCompaction()
#					import_operation.runHiveMajorCompaction()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# ******************************************
		# * IMPORT_PHASE_INCR & ETL_PHASE_MERGEHISTORYAUDIT
		# ******************************************
	
		if importPhase == constant.IMPORT_PHASE_INCR and etlPhase == constant.ETL_PHASE_MERGEHISTORYAUDIT and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1149 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
#				if stage == 3360: newStage = 3354 
				if stage == 3360: newStage = 3359 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			if runImportPhase == False and stage < 1149:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None:
				if import_operation.import_config.sqoop_last_rows == 0 and processEmptyTables == False:
					logging.info("No new rows have been imported. The ETL stage will be skipped")
					# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
					import_operation.setStage(3361)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3350) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3351) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()
					import_operation.createExternalImportView()
					import_operation.updateExternalImportView()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3352) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3353) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3354) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3355) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.convertHiveTableToACID()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=True)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "createHistoryTable":
				if import_operation.runStage(3356) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createHistoryTable()
					import_operation.updateHistoryTable()

			if runOnlyFunction == None or runOnlyFunction == "mergeTable":
				if import_operation.runStage(3357) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					importTableOrView = import_operation.import_config.Hive_Import_Table
					if import_operation.import_config.isExternalViewRequired() == True:
						importTableOrView = import_operation.import_config.Hive_Import_View
					etl_operation.mergeHiveTables(
						sourceDB = import_operation.import_config.Hive_Import_DB, 
						sourceTable = importTableOrView,
						targetDB = import_operation.import_config.Hive_DB, 
						targetTable = import_operation.import_config.Hive_Table, 
						historyDB = import_operation.import_config.Hive_History_DB, 
						historyTable = import_operation.import_config.Hive_History_Table, 
						createHistoryAudit = True,
						sourceIsIncremental = True,
						sourceIsImportTable = True,
						softDelete = None,
						mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
						datalakeSource = import_operation.import_config.datalake_source,
						PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True)
					)

				if import_operation.runStage(3358) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3359) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3360) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				if import_operation.runStage(3361) == True: 
					import_operation.saveIncrPendingValues()

			if runOnlyFunction == None or runOnlyFunction == "compaction":
				if import_operation.runStage(3362) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.runHiveCompaction()
#					import_operation.runHiveMajorCompaction()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# *******************************************************
		# * IMPORT_PHASE_ORACLE_FLASHBACK & ETL_PHASE_MERGEONLY
		# *******************************************************
	
		if importPhase == constant.IMPORT_PHASE_ORACLE_FLASHBACK and etlPhase == constant.ETL_PHASE_MERGEONLY and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1249 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				# TODO: Add correct restart points once incremental imports are working
				if stage == 3409: newStage = 3404 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()
	
			if runImportPhase == False and stage < 1249:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None:
				if import_operation.import_config.sqoop_last_rows == 0 and processEmptyTables == False:
					logging.info("No new rows have been imported. The ETL stage will be skipped")
					# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
					import_operation.setStage(3410)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3400) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3401) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()
					import_operation.createExternalImportView()
					import_operation.updateExternalImportView()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3402) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3403) == True: 
						import_operation.validateImportTable()
						import_operation.getImportViewRowCountAsSource(incr=True)

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3404) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3405) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.convertHiveTableToACID()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=True)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "mergeTable":
				if import_operation.runStage(3406) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

					if import_operation.import_config.isExternalViewRequired() == True:
						importTableOrView = import_operation.import_config.Hive_Import_View
					else:
						importTableOrView = import_operation.import_config.Hive_Import_Table

					if import_operation.import_config.incr_maxvalue == None: 
						# If it's an initial or reinitialized load, we need to remove old lines from target table
						deleteNotUpdatedRows = True
					else:
						deleteNotUpdatedRows = False

					etl_operation.mergeHiveTables(
						sourceDB = import_operation.import_config.Hive_Import_DB, 
						sourceTable = importTableOrView,
						targetDB = import_operation.import_config.Hive_DB, 
						targetTable = import_operation.import_config.Hive_Table, 
						createHistoryAudit = False,
						sourceIsIncremental = True,
						sourceIsImportTable = True,
						oracleFlashbackSource = True,
						softDelete = None,
						mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
						datalakeSource = import_operation.import_config.datalake_source,
						PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True),
						deleteNotUpdatedRows = deleteNotUpdatedRows
					)

				if import_operation.runStage(3407) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3408) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3409) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				if import_operation.runStage(3410) == True: 
					import_operation.saveIncrPendingValues()

			if runOnlyFunction == None or runOnlyFunction == "compaction":
				if import_operation.runStage(3411) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.runHiveCompaction()
#					import_operation.runHiveMajorCompaction()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# ******************************************
		# * IMPORT_PHASE_FULL & ETL_PHASE_NONE
		# ******************************************

		if importPhase == constant.IMPORT_PHASE_FULL and (etlPhase == constant.ETL_PHASE_NONE or etlPhase == constant.ETL_PHASE_EXTERNAL) and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1049 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				if stage == 3453: newStage = 3450 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()


			if runImportPhase == False and stage < 1049:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3450) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3451) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3452) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3453) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# ******************************************
		# * IMPORT_PHASE_MONGO_FULL & ETL_PHASE_TRUNCATEINSERT
		# ******************************************

		if importPhase == constant.IMPORT_PHASE_MONGO_FULL and etlPhase == constant.ETL_PHASE_TRUNCATEINSERT and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1349 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
#				if stage == 3503: newStage = 3500 
#				if stage == 3505: newStage = 3504
#				if stage == 3506: newStage = 3504
#				if stage == 3500: newStage = 3504
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()


			if runImportPhase == False and stage < 1349:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3500) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3501) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3502) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3503) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3504) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3505) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=False)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "truncateTargetTable":
				if import_operation.runStage(3506) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.truncateTargetTable()
		
			if runOnlyFunction == None or runOnlyFunction == "loadDataFromImportTable":
				if import_operation.runStage(3507) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.loadDataFromImportToTargetTable()

				if import_operation.runStage(3508) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3509) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3510) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# *******************************************************
		# * IMPORT_PHASE_ORACLE_FLASHBACK & ETL_PHASE_MERGEHISTORYAUDIT
		# *******************************************************
	
		if importPhase == constant.IMPORT_PHASE_ORACLE_FLASHBACK and etlPhase == constant.ETL_PHASE_MERGEHISTORYAUDIT and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1249 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				# TODO: Add correct restart points once incremental imports are working
				if stage == 3560: newStage = 3554 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()

			if runImportPhase == False and stage < 1249:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None:
				if import_operation.import_config.sqoop_last_rows == 0 and processEmptyTables == False:
					logging.info("No new rows have been imported. The ETL stage will be skipped")
					# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
					import_operation.setStage(3561)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3550) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3551) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()
					import_operation.createExternalImportView()
					import_operation.updateExternalImportView()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3552) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3553) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3554) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3555) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.convertHiveTableToACID()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=True)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "createHistoryTable":
				if import_operation.runStage(3556) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createHistoryTable()
					import_operation.updateHistoryTable()

			if runOnlyFunction == None or runOnlyFunction == "mergeTable":
				if import_operation.runStage(3557) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

					if import_operation.import_config.isExternalViewRequired() == True:
						importTableOrView = import_operation.import_config.Hive_Import_View
					else:
						importTableOrView = import_operation.import_config.Hive_Import_Table

					if import_operation.import_config.incr_maxvalue == None: 
						# If it's an initial or reinitialized load, we need to remove old lines from target table
						deleteNotUpdatedRows = True
					else:
						deleteNotUpdatedRows = False

					etl_operation.mergeHiveTables(
						sourceDB = import_operation.import_config.Hive_Import_DB, 
						sourceTable = importTableOrView,
						targetDB = import_operation.import_config.Hive_DB, 
						targetTable = import_operation.import_config.Hive_Table, 
						historyDB = import_operation.import_config.Hive_History_DB, 
						historyTable = import_operation.import_config.Hive_History_Table, 
						createHistoryAudit = True,
						sourceIsIncremental = True,
						sourceIsImportTable = True,
						oracleFlashbackSource = True,
						softDelete = None,
						mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
						datalakeSource = import_operation.import_config.datalake_source,
						PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True),
						deleteNotUpdatedRows = deleteNotUpdatedRows,
						oracleFlashbackImportTable = import_operation.import_config.Hive_Import_Table
					)

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3559) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportViewRowCountAsSource(incr = True)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3560) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				if import_operation.runStage(3561) == True: 
					import_operation.saveIncrPendingValues()

			if runOnlyFunction == None or runOnlyFunction == "compaction":
				if import_operation.runStage(3562) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.runHiveCompaction()
#					import_operation.runHiveMajorCompaction()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()


		# *******************************************************
		# * IMPORT_PHASE_MSSQL_CHANGE_TRACKING & ETL_PHASE_MERGEONLY
		# *******************************************************
	
		if importPhase == constant.IMPORT_PHASE_MSSQL_CHANGE_TRACKING and etlPhase == constant.ETL_PHASE_MERGEONLY and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1299 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				# TODO: Add correct restart points once incremental imports are working
				if stage == 3603: newStage = 3600 
				if stage == 3607: newStage = 3604 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()
	
			if runImportPhase == False and stage < 1299:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None:
				if import_operation.import_config.sqoop_last_rows == 0 and processEmptyTables == False:
					logging.info("No new rows have been imported. The ETL stage will be skipped")
					# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
					import_operation.setStage(3610)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3600) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3601) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3602) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3603) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3604) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3605) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.convertHiveTableToACID()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=True)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "mergeTable":
				if import_operation.runStage(3607) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

					if import_operation.import_config.isExternalViewRequired() == True:
						importTableOrView = import_operation.import_config.Hive_Import_View
					else:
						importTableOrView = import_operation.import_config.Hive_Import_Table

					if import_operation.import_config.incr_maxvalue == None: 
						# If it's an initial or reinitialized load, we need to remove old lines from target table
						deleteNotUpdatedRows = True
					else:
						deleteNotUpdatedRows = False

					etl_operation.mergeHiveTables(
						sourceDB = import_operation.import_config.Hive_Import_DB, 
						sourceTable = importTableOrView,
						targetDB = import_operation.import_config.Hive_DB, 
						targetTable = import_operation.import_config.Hive_Table, 
						createHistoryAudit = False,
						sourceIsIncremental = True,
						sourceIsImportTable = True,
						mssqlChangeTrackingSource = True,
						softDelete = None,
						mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
						datalakeSource = import_operation.import_config.datalake_source,
						PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True),
						deleteNotUpdatedRows = deleteNotUpdatedRows
					)

				if import_operation.runStage(3608) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3609) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3610) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				if import_operation.runStage(3611) == True: 
					import_operation.saveIncrPendingValues()

			if runOnlyFunction == None or runOnlyFunction == "compaction":
				if import_operation.runStage(3612) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.runHiveCompaction()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()


		# *******************************************************
		# * IMPORT_PHASE_MSSQL_CHANGE_TRACKING & ETL_PHASE_MERGEHISTORYAUDIT
		# *******************************************************
	
		if importPhase == constant.IMPORT_PHASE_MSSQL_CHANGE_TRACKING and etlPhase == constant.ETL_PHASE_MERGEHISTORYAUDIT and runETLPhase == True:
			stage = import_operation.getStage()
			if stage > 0 and stage != 1299 and stage != 2099 and runOnlyFunction == None:
				import_operation.saveRetryAttempt(stage)

				newStage = 0
				# TODO: Add correct restart points once incremental imports are working
				if stage == 3653: newStage = 3650 
				if stage == 3657: newStage = 3654 
				print(" ________________________________________________________ ")
				print("|                                                        |")
				print("| WARNING: The previous import failed and this execution |") 	
				print("|          is recovering from that failure.              |") 	
				print("| Last execution failed on stage %s                    |"%(stage)) 	
				if newStage != 0: 
					print("| Will restart from stage %s                           |"%(newStage)) 	
					import_operation.setStage(newStage, force=True)
				print("|________________________________________________________|")
				print("")
				print("")
				sys.stdout.flush()
	
			if runImportPhase == False and stage < 1299:
				logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
				logging.error("Please run a import phase first and make sure it completes successfully")
				import_operation.remove_temporary_files()
				sys.exit(0)

			if runOnlyFunction == None:
				if import_operation.import_config.sqoop_last_rows == 0 and processEmptyTables == False:
					logging.info("No new rows have been imported. The ETL stage will be skipped")
					# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
					import_operation.setStage(3660)

			if runOnlyFunction == None or runOnlyFunction == "createImportTable":
				if import_operation.runStage(3650) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

				if import_operation.runStage(3651) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createExternalImportTable()
					import_operation.updateExternalImportTable()

			if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3652) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getImportTableValidationData()

					if import_operation.runStage(3653) == True: 
						import_operation.validateImportTable()

			if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
				if import_operation.runStage(3654) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.removeHiveLocks()

			if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
				if import_operation.runStage(3655) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createTargetTable()
					import_operation.convertHiveTableToACID()
					import_operation.updateTargetTable()
					import_operation.addHiveDBImportColumns(mergeOperation=True)
					import_operation.updatePKonTargetTable()
					import_operation.updateFKonTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "createHistoryTable":
				if import_operation.runStage(3656) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.createHistoryTable()
					import_operation.updateHistoryTable()

			if runOnlyFunction == None or runOnlyFunction == "mergeTable":
				if import_operation.runStage(3657) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)

					if import_operation.import_config.isExternalViewRequired() == True:
						importTableOrView = import_operation.import_config.Hive_Import_View
					else:
						importTableOrView = import_operation.import_config.Hive_Import_Table

					if import_operation.import_config.incr_maxvalue == None: 
						# If it's an initial or reinitialized load, we need to remove old lines from target table
						deleteNotUpdatedRows = True
					else:
						deleteNotUpdatedRows = False

					etl_operation.mergeHiveTables(
						sourceDB = import_operation.import_config.Hive_Import_DB, 
						sourceTable = importTableOrView,
						targetDB = import_operation.import_config.Hive_DB, 
						targetTable = import_operation.import_config.Hive_Table, 
						historyDB = import_operation.import_config.Hive_History_DB, 
						historyTable = import_operation.import_config.Hive_History_Table, 
						createHistoryAudit = True,
						sourceIsIncremental = True,
						sourceIsImportTable = True,
						mssqlChangeTrackingSource = True,
						softDelete = None,
						mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
						datalakeSource = import_operation.import_config.datalake_source,
						PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True),
						deleteNotUpdatedRows = deleteNotUpdatedRows,
						mssqlChangeTrackingImportTable = import_operation.import_config.Hive_Import_Table
					)

				if import_operation.runStage(3658) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.updateStatisticsOnTargetTable()

			if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
				if import_operation.import_config.validate_import == True:
					if import_operation.runStage(3659) == True: 
						import_operation.connectToHive(forceSkipTest=skipHiveTest)
						import_operation.getTargetTableValidationData()

					if import_operation.runStage(3660) == True: 
						import_operation.validateTargetTable()

			if runOnlyFunction == None:
				if import_operation.runStage(3661) == True: 
					import_operation.saveIncrPendingValues()

			if runOnlyFunction == None or runOnlyFunction == "compaction":
				if import_operation.runStage(3662) == True: 
					import_operation.connectToHive(forceSkipTest=skipHiveTest)
					import_operation.runHiveCompaction()

			if runOnlyFunction == None:
				import_operation.setStage(9999)

			if runOnlyFunction == None or runOnlyFunction == "createStatistics":
				import_operation.convertStageStatisticsToJSON()
				import_operation.saveStageStatistics()

		# ******************************************
		# * Print Import information
		# ******************************************

		if import_operation.getStage() == 9999: 
			if runOnlyFunction == None:
				if runImportPhase == True and runETLPhase == False:
					print(" ___________________________________ ")
					print("|                                   |")
					print("| Import Phase completed successful |") 	
					print("|___________________________________|")
				elif runImportPhase == False and runETLPhase == True:
					print(" ________________________________ ")
					print("|                                |")
					print("| ETL Phase completed successful |") 	
					print("|________________________________|")
				else:
					print(" _____________________________ ")
					print("|                             |")
					print("| Import completed successful |") 	
					print("|_____________________________|")
				print("")

#				if runETLPhase == True:
#					# We can only clear the stage at the end of stage 2. 
#					import_operation.clearStage()

		import_operation.import_config.common_config.disconnectFromJDBC()
		import_operation.remove_temporary_files()

	# Error handling for the entire stage block
	except SQLerror as errMsg:
		logging.error(errMsg)
		import_operation.import_config.remove_temporary_files()
		sys.exit(1)
	except validationError as errMsg:
		import_operation.import_config.remove_temporary_files()
		sys.exit(1)
	except invalidConfiguration as errMsg:
		logging.error(errMsg)
		import_operation.import_config.remove_temporary_files()
		sys.exit(1)
	except daemonExit as errMsg:
		logging.error("Program exit because requested to do so by developer. %s"%(errMsg))
		import_operation.import_config.remove_temporary_files()
		sys.exit(1)
	except:
		import_operation.import_config.remove_temporary_files()
		raise
		sys.exit(1)

if __name__ == "__main__":
	main(sys.argv[1:])

