import { SettingType } from './enums'
import {
  CustomAirflowDAG,
  EditSetting,
  ExportAirflowDAG,
  ImportAirflowDAG
} from './interfaces'

export function airflowCardRenderSettings(
  airflowType: 'import' | 'export' | 'custom',
  dagData: ImportAirflowDAG | ExportAirflowDAG | CustomAirflowDAG
) {
  const baseAirflowDagSettings: EditSetting[] = [
    {
      label: 'DAG Name',
      value: dagData.name,
      type: SettingType.Readonly
    }, // Readonly, varchar(64), have to be unique across import, export and custom, required
    {
      label: 'Schedule Interval',
      value: dagData.scheduleInterval,
      type: SettingType.Text
    }, // Free-text, Time to execute DAG, varchar(128), required

    {
      label: 'Retries',
      value: dagData.retries,
      type: SettingType.IntegerFromZero
    }, // Integer, tinyint(4), default value: 5 for import & export and 0 for custom, How many retries should be Task do in Airflow before it failes,  required
    {
      label: 'Operator Notes',
      value: dagData.operatorNotes,
      type: SettingType.Textarea
    }, // Free-text (64k)
    {
      label: 'Application Notes',
      value: dagData.applicationNotes,
      type: SettingType.Textarea
    }, // Free-text (64k)
    {
      label: 'Auto Regenerate DAG',
      value: dagData.autoRegenerateDag,
      type: SettingType.Boolean
    }, // Boolean, if not set pre-set default value: 1, 1 = The DAG will be auto regenerated by manage command, required
    {
      label: 'Airflow Notes',
      value: dagData.airflowNotes,
      type: SettingType.Textarea
    }, // Free-text (64k)
    {
      label: 'Sudo User',
      value: dagData.sudoUser,
      type: SettingType.Text
    }, // Free-text, varchar(64), All tasks in DAG will use this user for sudo instead of default
    {
      label: 'Timezone',
      value: dagData.timezone,
      type: SettingType.TimeZone
    }, // Timezone,, varchar(64), used for schedule_interval column. Use full text timezone, example Europe/Stockholm
    {
      label: 'Email',
      value: dagData.email,
      type: SettingType.Email,
      isConditionsMet:
        dagData.emailOnRetries === true || dagData.emailOnFailure === true
    }, // Free-text, varchar(256), Email to send message to in case email_on_retry or email_on_failure is set to True
    {
      label: 'Email On Failure',
      value: dagData.emailOnFailure ? dagData.emailOnFailure : false,
      type: SettingType.Boolean
    }, // Boolean, if not set pre-set default value: false, Send email on failures, required
    {
      label: 'Email On Retries',
      value: dagData.emailOnRetries ? dagData.emailOnRetries : false,
      type: SettingType.Boolean
    }, // Boolean, if not set pre-set default value: false, Send email on retries, required
    {
      label: 'Tags',
      value: dagData.tags,
      type: SettingType.Text
    }, // Free-text, varchar(256), Comma seperated list of Airflow tags that will be set on the DAG
    {
      label: 'Sla Warning Time',
      value: dagData.slaWarningTime,
      type: SettingType.Time
    }, // Time, Maximum time this DAG should run before Airflow triggers a SLA miss
    {
      label: 'Retry Exponential Backoff',
      value: dagData.retryExponentialBackoff
        ? dagData.retryExponentialBackoff
        : false,
      type: SettingType.Boolean
    }, // Boolean, if not set pre-set default value: false, true=Use the retry_exponential_backoff Airflow function that will cause the retry between failed tasks to be longer and longer each time instead of a fixed time, false=Run with a fixed time of 5 min between the task retries, required
    {
      label: 'Concurrency',
      value: dagData.concurrency,
      type: SettingType.IntegerFromOneOrNull //has to be at least one, or null
    } // Integer, tinyint(4), Set the max Integer of concurrent tasks in the DAG while executing. Overrides the default value specified in Airflow configuration
  ]

  const airflowImportDagSettings: EditSetting[] =
    'filterTable' in dagData
      ? [
          {
            label: 'Filter Table',
            value: dagData.filterTable, // column filter_hive in db
            type: SettingType.Textarea
          }, // Free-text, varchar(16384), Filter string for database and table. ; separated. Wildcards (*) allowed. Example HIVE_DB.HIVE_TABLE; HIVE_DB.HIVE_TABLE, required
          {
            label: 'Finish all Stage 1 first',
            value: dagData.finishAllStage1First,
            type: SettingType.Boolean
          }, // Boolean, if not set pre-set default value: false, true=All Import phase jobs will be completed first, and when all is successfull, the ETL phase start, required
          {
            label: 'Retries Import Stage',
            value: dagData.retriesStage1,
            type: SettingType.IntegerFromOneOrNull
          }, // Integer, tinyint(4), Specific retries Integer for Import Phase
          {
            label: 'Retries ETL Stage',
            value: dagData.retriesStage2,
            type: SettingType.IntegerFromOneOrNull
          }, // Integer, tinyint(4), Specific retries Integer for Import Phase
          {
            label: 'Pool Import Stage',
            value: dagData.poolStage1,
            type: SettingType.Text
          }, // Free-text, varchar(256), Airflow pool used for stage1 tasks. NULL for the default Hostname pool
          {
            label: 'Pool ETL Stage',
            value: dagData.poolStage2,
            type: SettingType.Text
          }, // Free-text, varchar(256), Airflow pool used for stage2 tasks. NULL for the default DAG pool
          {
            label: 'Run Only Metadata Import',
            value: dagData.metadataImport,
            type: SettingType.Boolean // maybe make new SettingType
          }, // Boolean, if not set pre-set default value: false, required
          {
            label: 'Run Import and Etl separate',
            value: dagData.runImportAndEtlSeparate,
            type: SettingType.Boolean // maybe make new SettingType
          } // Boolean, if not set pre-set default value: true, required
        ]
      : []

  const airflowExportDagSettings: EditSetting[] =
    'filterConnection' in dagData
      ? [
          {
            label: 'Filter Connection',
            value: dagData.filterConnection, // column filter_hive in db
            type: SettingType.Text
          }, // Free-text, varchar(256), Filter string for DBALIAS in export_tables, required
          {
            label: 'Filter Target Schema',
            value: dagData.filterTargetSchema,
            type: SettingType.Text
          }, // Free-text, varchar(256), Filter string for TARGET_SCHEMA  in export_tables
          {
            label: 'Filter Target Table',
            value: dagData.filterTargetTable,
            type: SettingType.Text
          } // Free-text, varchar(256), Filter string for TARGET_TABLE  in export_tables
        ]
      : []

  const airflowCustomDagSettings: EditSetting[] = baseAirflowDagSettings

  let combinedAirflowDagSettings

  switch (airflowType) {
    case 'import':
      return (combinedAirflowDagSettings = [
        ...baseAirflowDagSettings,
        ...airflowImportDagSettings
      ])
    case 'export':
      return (combinedAirflowDagSettings = [
        ...baseAirflowDagSettings,
        ...airflowExportDagSettings
      ])
    case 'custom':
      return (combinedAirflowDagSettings = airflowCustomDagSettings)
  }

  return combinedAirflowDagSettings
}

export function createAirflowSettings(
  airflowType: 'import' | 'export' | 'custom'
) {
  const baseAirflowDagSettings: EditSetting[] = [
    { label: 'DAG Name', value: null, type: SettingType.Text }, //Free-text, varchar(64), have to be unique across import, export and custom, required
    { label: 'Schedule Interval', value: null, type: SettingType.Text }, // Free-text, Time to execute DAG, varchar(128), required
    {
      label: 'Auto Regenerate DAG',
      value: true,
      type: SettingType.Boolean
    } // Boolean, if not set pre-set default value: true, true = The DAG will be auto regenerated by manage command, required
  ]

  const airflowImportDagSettings: EditSetting[] = [
    {
      label: 'Filter Table',
      value: null,
      type: SettingType.Text
    } // Free-text, varchar(16384), Filter string for database and table. ; separated. Wildcards (*) allowed. Example HIVE_DB.HIVE_TABLE; HIVE_DB.HIVE_TABLE, required
  ]

  const airflowExportDagSettings: EditSetting[] = [
    {
      label: 'Filter Connection',
      value: null, // column filter_hive in db
      type: SettingType.Text
    }, // Free-text, varchar(256), Filter string for DBALIAS in export_tables
    {
      label: 'Filter Target Schema',
      value: null,
      type: SettingType.Text
    }, // Free-text, varchar(256), Filter string for TARGET_SCHEMA  in export_tables
    {
      label: 'Filter Target Table',
      value: null,
      type: SettingType.Text
    } // Free-text, varchar(256), Filter string for TARGET_TABLE  in export_tables
  ]

  const airflowCustomDagSettings: EditSetting[] = baseAirflowDagSettings

  let combinedAirflowDagSettings

  switch (airflowType) {
    case 'import':
      return (combinedAirflowDagSettings = [
        ...baseAirflowDagSettings,
        ...airflowImportDagSettings
      ])
    case 'export':
      return (combinedAirflowDagSettings = [
        ...baseAirflowDagSettings,
        ...airflowExportDagSettings
      ])
    case 'custom':
      return (combinedAirflowDagSettings = airflowCustomDagSettings)
  }

  return combinedAirflowDagSettings
}
