#!/usr/bin/env python3
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import sys
import getopt
import logging
from common import constants as constant
from DBImportConfig import common_config
from DBImportOperation import common_operations
from DBImportOperation import import_operations
from DBImportOperation import export_operations
from DBImportOperation import copy_operations
from Schedule import Airflow

def	printHeader():
	# Font created at http://patorjk.com/software/taag/#p=display&f=Big&t=DBImport%20-%20Deploy
	sys.stdout.write(u"\u001b[35m")  # Magenta
	sys.stdout.flush()
	print("")
	print("   _____  ____ _____                            _              _____             _              ")
	print("  |  __ \|  _ \_   _|                          | |            |  __ \           | |             ")
	print("  | |  | | |_) || |  _ __ ___  _ __   ___  _ __| |_   ______  | |  | | ___ _ __ | | ___  _   _  ")
	print("  | |  | |  _ < | | | '_ ` _ \| '_ \ / _ \| '__| __| |______| | |  | |/ _ \ '_ \| |/ _ \| | | | ")
	print("  | |__| | |_) || |_| | | | | | |_) | (_) | |  | |_           | |__| |  __/ |_) | | (_) | |_| | ")
	print("  |_____/|____/_____|_| |_| |_| .__/ \___/|_|   \__|          |_____/ \___| .__/|_|\___/ \__, | ")
	print("                              | |                                         | |             __/ | ")
	print("                              |_|                                         |_|            |___/  ")
	sys.stdout.write(u"\u001b[0m")  # Reset
	sys.stdout.flush()
	print("")
	print("Version: %s"%(constant.VERSION))
	print("")

def printMainHelp():
	printHeader()
	print ("Options:")
	print ("  --deployAirflowImportDAG          Deploy an Airflow DAG and all import tables that goes with it")
	print ("  --deployAirflowExportDAG          Deploy an Airflow DAG and all export tables that goes with it")
#	print ("  --deployImportDatabase            Deploy all import tables that is configured in the database")
#	print ("  --deployExportDatabase            Deploy all export tables that is configured in the database")
#	print ("  --deployImportTable               Deploy an import table")
#	print ("  --deployExportTable               Deploy an export table")
	print ("")
	print ("General parameters to all commands:")
	print ("  --help             Show this help message and exit")
	print ("  -v, --debug        Turn on extensive debug output. This will print passwords in cleartext, so use with caution")
	print ("  --quiet            Suppress logo and version output")

	sys.exit(1)

def print_deployAirflowImportDAG_help():
	printHeader()
	print ("Deploy the DAG definition and all involved databases, tables and connection aliases to a remote DBImport instance" )
	print ("If the DAG already exists in the remote DBImport instance, all definitions will be updated. Keep in mind that if a table")
	print ("exists in the remote DBImport instance, but not in the source, the table wont be deleted from the remote DBImport instance")
	print ("")
	print ("Required parameters:")
	print ("  --airflowDAG=[DAG name]        Name of the DAG to deploy.")
	print ("  --deployTarget=[Instance]      Name of the DBImport instance to where you want to deploy")
	print ("")
	sys.exit(1)

def print_deployAirflowExportDAG_help():
	printHeader()
	print ("Deploy the DAG definition and all involved databases, tables and connection aliases to a remote DBImport instance" )
	print ("If the DAG already exists in the remote DBImport instance, all definitions will be updated. Keep in mind that if a table")
	print ("exists in the remote DBImport instance, but not in the source, the table wont be deleted from the remote DBImport instance")
	print ("")
	print ("Required parameters:")
	print ("  --airflowDAG=[DAG name]        Name of the DAG to deploy.")
	print ("  --deployTarget=[Instance]      Name of the DBImport instance to where you want to deploy")
	print ("")
	sys.exit(1)

def main(argv):
	try:
		opts, args = getopt.getopt(argv, "?yvwh:t:a:S:T:", ["quiet", "yes", "help", "Hive_DB=", "hiveDB=", "Hive_Table=", "hiveTable=", "dbAlias=", "debug", "airflowDAG=", "deployTarget=", "deployAirflowImportDAG", "deployAirflowExportDAG", "deployImportDatabase", "deployExportDatabase", "deployImportTable", "deployExportTable" ])
	except getopt.GetoptError:
		printMainHelp()

	Hive_DB = None
	Hive_Table = None
	displayHelp = False
	operation = None
	loggingLevel = logging.INFO
	autoYesAnswer = False
	airflowDAG = None
	deployTarget = None
	quietMode = False

	if len(opts) == 0:
		printMainHelp()

	for opt, arg in opts:
		if opt in ("-?", "--help"):
			displayHelp = True
		elif opt in ("-y", "--yes"):
			autoYesAnswer = True
		elif opt in ("-v", "--debug"):
			loggingLevel = logging.DEBUG
		elif opt in ("-h", "--hiveDB", "--Hive_DB"):
			Hive_DB = arg
		elif opt in ("-t", "--hiveTable", "--Hive_Table"):
			Hive_Table = arg
		elif opt == "--quiet":
			quietMode = True
		elif opt == "--deployTarget":
			deployTarget = str(arg)
		elif opt == "--airflowDAG":
			airflowDAG = str(arg)
		elif opt == "--deployAirflowImportDAG":
			operation = "deployAirflowImportDAG"
		elif opt == "--deployAirflowExportDAG":
			operation = "deployAirflowExportDAG"
#		elif opt == "--deployImportDatabase":
#			operation = "deployImportDatabase"
#		elif opt == "--deployExportDatabase":
#			operation = "deployExportDatabase"
#		elif opt == "--deployImportTable":
#			operation = "deployImportTable"
#		elif opt == "--deployExportTable":
#			operation = "deployExportTable"

	if operation == None:
		printMainHelp()

	if operation == "deployAirflowImportDAG" and (airflowDAG == None or deployTarget == None or displayHelp == True):
		print_deployAirflowImportDAG_help()

	if operation == "deployAirflowExportDAG" and (airflowDAG == None or deployTarget == None or displayHelp == True):
		print_deployAirflowExportDAG_help()

	if quietMode == False:
		printHeader()

	# Initiate the logging functions with the correct level
	if loggingLevel == logging.DEBUG:
		logging.basicConfig(format='%(levelname)s %(funcName)s - %(message)s', level=loggingLevel)
	else:
		logging.basicConfig(format='%(levelname)s - %(message)s', level=loggingLevel)

	if operation == "deployAirflowImportDAG":
		copyOperation = copy_operations.operation()
		copyOperation.checkRemoteInstanceSchema(remoteInstance = deployTarget)
		copyOperation.copyAirflowImportDAG(airflowDAGname = airflowDAG, copyDestination = deployTarget, deployMode = True)
		copyOperation.remove_temporary_files()

	if operation == "deployAirflowExportDAG":
		copyOperation = copy_operations.operation()
		copyOperation.checkRemoteInstanceSchema(remoteInstance = deployTarget)
		copyOperation.copyAirflowExportDAG(airflowDAGname = airflowDAG, copyDestination = deployTarget, deployMode = True)
		copyOperation.remove_temporary_files()


if __name__ == "__main__":
	main(sys.argv[1:])
